# README: PDF Estimation using Generative Adversarial Networks (GAN)

## Project Overview
[cite_start]This project implements a Generative Adversarial Network (GAN) to learn and model the unknown probability density function (PDF) of a transformed random variable[cite: 5, 10]. [cite_start]The source data consists of $NO_{2}$ concentration levels from the India Air Quality dataset[cite: 2, 3].

## Transformation Parameters
[cite_start]The following parameters were calculated using the university roll number (r)[cite: 9]:
* [cite_start]**$a\_r$**: $0.5 * (r \mod 7)$ [cite: 8]
* [cite_start]**$b\_r$**: $0.3 * (r \mod 5 + 1)$ [cite: 8]
* [cite_start]**Transformation Formula**: $z = x + a\_r * \sin(b\_r * x)$ [cite: 7]

## GAN Architecture
[cite_start]The implementation utilizes two neural networks that compete against each other[cite: 15]:
* [cite_start]**Generator**: A multi-layer perceptron that transforms Gaussian noise $N(0,1)$ into fake samples $z\_f$[cite: 21].
* [cite_start]**Discriminator**: A binary classifier designed to distinguish between real transformed samples (z) and fake samples generated by the network[cite: 19, 20].

## Methodology
1. [cite_start]**Data Preprocessing**: $NO_{2}$ features are extracted and normalized[cite: 2].
2. [cite_start]**Feature Transformation**: Each feature value is processed through the $Tr(x)$ function[cite: 7].
3. [cite_start]**Implicit Modeling**: The GAN learns the distribution without assuming any parametric form like Gaussian or Exponential[cite: 16, 18].
4. [cite_start]**Density Estimation**: After training, the generator produces 10,000 samples which are then used to estimate the PDF via Kernel Density Estimation (KDE)[cite: 24, 25, 26].

## Deliverables
* [cite_start]Calculated transformation parameters[cite: 28].
* [cite_start]GAN architecture specifications[cite: 29].
* [cite_start]Visualized PDF plot (`pdf_plot.png`)[cite: 30].
* [cite_start]Observations regarding training stability and distribution quality[cite: 33, 34].
